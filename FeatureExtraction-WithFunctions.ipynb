{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a2e0cf",
   "metadata": {},
   "source": [
    "# Done by Mohammad Navid Nayyem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9d465",
   "metadata": {},
   "source": [
    "## Import Libraries and Downloads for SMS Text Processing and Bag-of-Words (BoW) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688171dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohammad\n",
      "[nltk_data]     Navid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohammad\n",
      "[nltk_data]     Navid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Required for handling and analyzing data in tabular format\n",
    "import re  # Required for working with regular expressions\n",
    "import nltk  # Required for natural language processing tasks like tokenization, stemming, and more.\n",
    "from nltk.tokenize import word_tokenize # Required for tokenization\n",
    "from nltk.corpus import stopwords # Required for removing the stopword\n",
    "nltk.download('stopwords') # Download NLTK stopwords\n",
    "nltk.download('punkt') # Download NLTK punctuations\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Required for training BoW model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84fcabc",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5a5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for each data preprocessing step\n",
    "\n",
    "def load_data():\n",
    "    # B1. Load the dataset\n",
    "    data_SMS = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=[\"Class\", \"SMS_Text\"])\n",
    "    #print(data_SMS)\n",
    "    return data_SMS\n",
    "\n",
    "def preprocess_text(data_SMS):\n",
    "    # B2. Perform case normalization (lower case) to the text data\n",
    "    data_SMS['PREPROCESSED_SMS'] = data_SMS['SMS_Text'].str.lower()\n",
    "    #print(data_SMS['PREPROCESSED_SMS'])\n",
    "    return data_SMS\n",
    "\n",
    "def remove_punctuations_digits(data_SMS):\n",
    "    # B3. Remove the punctuations and digits from the text data\n",
    "    data_SMS['PREPROCESSED_SMS'] = data_SMS['PREPROCESSED_SMS'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', ' ', x))\n",
    "    #print(data_SMS['PREPROCESSED_SMS'])\n",
    "    return data_SMS\n",
    "\n",
    "def tokenize_text(data_SMS):\n",
    "    # B4. Tokenize the text data\n",
    "    data_SMS['PREPROCESSED_SMS'] = data_SMS['PREPROCESSED_SMS'].apply(word_tokenize)\n",
    "    #print(data_SMS['PREPROCESSED_SMS'])\n",
    "    return data_SMS\n",
    "\n",
    "def remove_stopwords(data_SMS):\n",
    "    # B5. Remove the stopwords from text data\n",
    "    StopwordsEnglish = stopwords.words('english')\n",
    "    data_SMS['StopwordsRemoved'] = data_SMS['PREPROCESSED_SMS'].apply(lambda x: [word for word in x if word not in StopwordsEnglish])\n",
    "    #print(data_SMS['StopwordsRemoved'])\n",
    "    return data_SMS\n",
    "\n",
    "def train_bow_model(data_SMS):\n",
    "    # B6. Train the BoW model\n",
    "    SMS_vectorizer = CountVectorizer()\n",
    "    SMS_bow = SMS_vectorizer.fit_transform(data_SMS['StopwordsRemoved'].apply(lambda x: ' '.join(x)))\n",
    "    SMS_bow.toarray()\n",
    "    return SMS_bow, SMS_vectorizer\n",
    "\n",
    "def print_feature_names(SMS_vectorizer):\n",
    "    # B7. Print out the names of the features\n",
    "    print(SMS_vectorizer.get_feature_names_out())\n",
    "\n",
    "def convert_bow_matrix_to_df(SMS_bow, SMS_vectorizer):\n",
    "    # B8. Transform BoW matrix into Pandas DataFrame\n",
    "    bow_df = pd.DataFrame(SMS_bow.toarray(), columns=SMS_vectorizer.get_feature_names_out())\n",
    "    print(bow_df)\n",
    "    return bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb7f6e",
   "metadata": {},
   "source": [
    "## Main Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd69481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aah' 'aaniye' ... 'zouk' 'zs' 'zyada']\n",
      "      aa  aah  aaniye  aaooooright  aathi  ab  abbey  abdomen  abeg  abel  \\\n",
      "0      0    0       0            0      0   0      0        0     0     0   \n",
      "1      0    0       0            0      0   0      0        0     0     0   \n",
      "2      0    0       0            0      0   0      0        0     0     0   \n",
      "3      0    0       0            0      0   0      0        0     0     0   \n",
      "4      0    0       0            0      0   0      0        0     0     0   \n",
      "...   ..  ...     ...          ...    ...  ..    ...      ...   ...   ...   \n",
      "5567   0    0       0            0      0   0      0        0     0     0   \n",
      "5568   0    0       0            0      0   0      0        0     0     0   \n",
      "5569   0    0       0            0      0   0      0        0     0     0   \n",
      "5570   0    0       0            0      0   0      0        0     0     0   \n",
      "5571   0    0       0            0      0   0      0        0     0     0   \n",
      "\n",
      "      ...  zeros  zf  zhong  zindgi  zoe  zogtorius  zoom  zouk  zs  zyada  \n",
      "0     ...      0   0      0       0    0          0     0     0   0      0  \n",
      "1     ...      0   0      0       0    0          0     0     0   0      0  \n",
      "2     ...      0   0      0       0    0          0     0     0   0      0  \n",
      "3     ...      0   0      0       0    0          0     0     0   0      0  \n",
      "4     ...      0   0      0       0    0          0     0     0   0      0  \n",
      "...   ...    ...  ..    ...     ...  ...        ...   ...   ...  ..    ...  \n",
      "5567  ...      0   0      0       0    0          0     0     0   0      0  \n",
      "5568  ...      0   0      0       0    0          0     0     0   0      0  \n",
      "5569  ...      0   0      0       0    0          0     0     0   0      0  \n",
      "5570  ...      0   0      0       0    0          0     0     0   0      0  \n",
      "5571  ...      0   0      0       0    0          0     0     0   0      0  \n",
      "\n",
      "[5572 rows x 7619 columns]\n"
     ]
    }
   ],
   "source": [
    "# Main function to execute the data preprocessing and transformation steps\n",
    "def main():\n",
    "    data_SMS = load_data()\n",
    "    preprocessed_data = preprocess_text(data_SMS)\n",
    "    punctuations_digits_removed_data=remove_punctuations_digits(preprocessed_data)\n",
    "    tokenized_data = tokenize_text(punctuations_digits_removed_data)\n",
    "    stopword_removed_data = remove_stopwords(tokenized_data)\n",
    "    SMS_bow, SMS_vectorizer = train_bow_model(stopword_removed_data)\n",
    "    print_feature_names(SMS_vectorizer)\n",
    "    bow_df = convert_bow_matrix_to_df(SMS_bow, SMS_vectorizer)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f7140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
